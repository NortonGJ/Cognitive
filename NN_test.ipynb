{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50575de",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 60\n",
    "La = 50\n",
    "N = T * La\n",
    "\n",
    "input_layers = N\n",
    "hidden_layer_1 = 1500\n",
    "hidden_layer_2 = 500\n",
    "output_layers = La"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "filename = 'test_data'\n",
    "labelname = filename + '_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afa47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(f'{data_dir}/{filename}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(f'{data_dir}/{labelname}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f56044",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 80\n",
    "num_train = int(x.shape[0] * split / 100)\n",
    "trainf = x[0:num_train]\n",
    "trainl = y[0:num_train]\n",
    "testf = x[num_train:x.shape[0]]\n",
    "testl = y[num_train:x.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.Tensor(X)\n",
    "        self.Y = torch.Tensor(Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index]), (self.Y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigmoid = nn.Sigmoid()\n",
    "Softmax = nn.Softmax()\n",
    "LinearSigmoid = nn.SiLU()\n",
    "class Net(nn.Module):\n",
    "    Sigmoid = nn.Sigmoid()\n",
    "    Softmax = nn.Softmax()\n",
    "    LinearSigmoid = nn.SiLU()\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_layers, hidden_layer_1)\n",
    "        self.fc2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.fc3 = nn.Linear(hidden_layer_2, output_layers)\n",
    "    def forward(self, x):\n",
    "        x = Sigmoid(self.fc1(x))\n",
    "        x = Sigmoid(self.fc2(x))\n",
    "        x = Softmax(self.fc3(x))\n",
    "        return x.view(-1)\n",
    "\n",
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,  dataset, net, loss_f, learning_rate=1e-3, \n",
    "                 epoch_amount=500,\n",
    "                 batch_size=80000,\n",
    "                 max_batches_per_epoch=None,\n",
    "                 device='cuda:0', early_stopping=10, \n",
    "                 optim=torch.optim.Adam, \n",
    "                 scheduler=None, permutate=True):\n",
    "        \n",
    "        self.loss_f = loss_f\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch_amount = epoch_amount\n",
    "        self.batch_size = batch_size\n",
    "        self.max_batches_per_epoch = max_batches_per_epoch\n",
    "        self.device = device\n",
    "        self.early_stopping = early_stopping\n",
    "        self.optim = optim\n",
    "        self.scheduler = scheduler\n",
    "        self.permutate = permutate\n",
    "        self.dataset = dataset\n",
    "        self.start_model = net\n",
    "        self.best_model = net\n",
    "\n",
    "        self.train_loss = []\n",
    "\n",
    "        self.final_c = []\n",
    "        self.final_p = []\n",
    "        self.best_model_n = []\n",
    "        ### NEW\n",
    "        self.train_perc = []\n",
    "        self.test_perc = [] \n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.best_model(X)\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):       \n",
    "        Net = self.start_model\n",
    "                  \n",
    "        device = torch.device(self.device)\n",
    "        print(device, y_train.shape[0], y_test.shape[0])\n",
    "        Net.to(self.device)\n",
    "        \n",
    "        optimizer = self.optim(Net.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        if self.scheduler is not None:\n",
    "            scheduler = self.scheduler(optimizer)\n",
    "        \n",
    "        train = self.dataset(X_train, y_train)\n",
    "        val = self.dataset(X_test, y_test)  \n",
    "        \n",
    "        train = DataLoader(train, batch_size=y_train.shape[0], shuffle = False) \n",
    "        val = DataLoader(val, batch_size=y_test.shape[0], shuffle = False)\n",
    "        \n",
    "        best_val_loss = float('inf') # Лучшее значение функции потерь на валидационной выборке\n",
    "                                     # функции потерь на валидационной выборке\n",
    "        best_ep = 0                  # Эпоха, на которой достигалось лучшее \n",
    "                                     # значение функции потерь на валидационной выборке\n",
    "        tStart = time.monotonic()\n",
    "        for epoch in range(self.epoch_amount): \n",
    "            Net.train()\n",
    "            mean_loss = 0\n",
    "            batch_n = 0\n",
    "            mean_pred = []\n",
    "            for batch_X, target in train:\n",
    "                optimizer.zero_grad()\n",
    "                batch_X = batch_X.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                predicted_values = Net(batch_X)\n",
    "                target = target.view(predicted_values.size()) \n",
    "\n",
    "                loss = self.loss_f(predicted_values, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if epoch == self.epoch_amount-1:\n",
    "                    self.final_c.append(batch_X.cpu().detach().numpy())\n",
    "                    self.final_p.append(predicted_values.cpu().detach().numpy())\n",
    "\n",
    "                mean_loss += float(loss)\n",
    "                batch_n += 1\n",
    "\n",
    "            mean_loss /= batch_n\n",
    "            self.train_loss.append(mean_loss)\n",
    "\n",
    "            if epoch == 0:\n",
    "                tt = mean_loss\n",
    "   \n",
    "            if epoch % 25 == 0:\n",
    "                tEnd = time.monotonic()\n",
    "                print('{:4} - {:.6f} - {:5.1f} sec'.format(epoch, mean_loss/tt, (tEnd - tStart)))\n",
    "                tStart = time.monotonic()\n",
    "            if epoch % 100 == 0:    \n",
    "                train_num = 0\n",
    "                num = 0\n",
    "                for batch_X, target in train:\n",
    "                    batch_X = batch_X.to(self.device)\n",
    "                    target = target.to(self.device)\n",
    "                    predicted_values = Net(batch_X)\n",
    "                    predicted_values = predicted_values.view(target.size())\n",
    "                    targetIND = torch.argmax(target, dim = 1)\n",
    "                    predictIND = torch.argmax(predicted_values, dim = 1)\n",
    "                    for i, j in zip(targetIND, predictIND):\n",
    "                        if i == j:\n",
    "                            train_num += 1\n",
    "                        num += 1\n",
    "                self.train_perc.append(train_num/num*100)\n",
    "                print('train - {:5.2f}%'.format(train_num/num*100), end = ' ')\n",
    "                val_num = 0\n",
    "                num = 0\n",
    "                for batch_X, target in val:\n",
    "                    batch_X = batch_X.to(self.device)\n",
    "                    target = target.to(self.device)\n",
    "                    predicted_values = Net(batch_X)\n",
    "                    predicted_values = predicted_values.view(target.size())\n",
    "                    targetIND = torch.argmax(target, dim = 1)\n",
    "                    predictIND = torch.argmax(predicted_values, dim = 1)\n",
    "                    for i, j in zip(targetIND, predictIND):\n",
    "                        if i == j:\n",
    "                            val_num += 1\n",
    "                        num += 1\n",
    "                self.test_perc.append(val_num/num*100)\n",
    "                print('test - {:5.2f}%'.format(val_num/num*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dataset': MyDataset,\n",
    "    'net': net,\n",
    "    'epoch_amount': 10000, \n",
    "    'learning_rate': 2e-4,\n",
    "    'early_stopping': 25,\n",
    "    'loss_f': nn.BCELoss(), # BCELoss, CrossEntropyLoss(), MSELoss()\n",
    "    'optim': torch.optim.Adam,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded148c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = Trainer(**params)\n",
    "clf.fit(trainf, testf, trainl, testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01992109",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "plt.plot(10*np.log10(np.asarray(clf.train_loss)/clf.train_loss[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "xt = np.asarray(range(len(clf.train_perc)))*100\n",
    "plt.plot(xt, np.asarray(clf.train_perc), color = 'red')\n",
    "plt.plot(xt, np.asarray(clf.test_perc), color = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(clf.train_perc)[-1], np.asarray(clf.test_perc)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eae3bc-de42-4a74-931c-2f9819e16763",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = './NN_states'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537dce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'epoch': np.asarray(clf.train_loss).shape[0],\n",
    "    'hidden_layers': (hidden_layer_1, hidden_layer_2),\n",
    "    'func_activ': (\"Logsig\", \"Logsig\"), \n",
    "    'state_dict' : net.state_dict(),\n",
    "    'optim': params['optim'],\n",
    "    'loss_f': \"BCELoss\",\n",
    "    'train_test': (np.asarray(clf.train_perc)[-1], np.asarray(clf.test_perc)[-1]),\n",
    "    'data_dir': data_dir,\n",
    "    'labels': labelname\n",
    "}\n",
    "\n",
    "torch.save(state, f\"{savedir}/{labelname}_test.st\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
